{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basics of Image Formation"
      ],
      "metadata": {
        "id": "TB2jY0yXLW2A"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlc_G7qwfUPs"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj-5RVJeHuoq"
      },
      "source": [
        "!git clone https://github.com/IVRL/CS413-ComputationalPhotography.git\n",
        "%cd \"CS413-ComputationalPhotography/Homework 1 Basics Image Formation\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0T2NqPvIACC"
      },
      "source": [
        "from helper import plot_spectrum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zqF01oTQjyt"
      },
      "source": [
        "## Illuminants\n",
        "\n",
        "Perfectly white light has equal power in all wavelengths of light. In reality, light sources have non-uniform spectral power distributions, i.e., they vary in the amount of power they emit at different wavelengths $\\lambda$.\n",
        "\n",
        "We provide you 4 files, `A.npy`, `D50.npy`, `D65.npy`, `F2.npy`.\n",
        "These files contain the spectral power distribution $E(\\lambda)$ of various light sources."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFbhxsmkMO7I"
      },
      "source": [
        "!ls illuminants/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Those files can be loaded as follow:"
      ],
      "metadata": {
        "id": "f_oOoSRJTj54"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMmc4RceMmua"
      },
      "source": [
        "illuminant_d65 = np.load(os.path.join('illuminants', 'D65.npy'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The array `illuminant` contains two columns. The first column specifies a wavelength $\\lambda$ (in $nm$) and the second column specifies the relative power $E(\\lambda)$ measured at that wavelength.\n",
        "\n",
        "We print the five first rows of this array:"
      ],
      "metadata": {
        "id": "qJxvnGGdTwLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(illuminant_d65[:5, :])"
      ],
      "metadata": {
        "id": "kd9kZWUjTwdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the file `helpers.py`, we provide a function `plot_spectrum(x, y, ylabel)`. `x` and `y` must be two 1-dimensional arrays corresponding to the grid of wavelengths $\\lambda$ and corresponding relative power values $E(\\lambda)$.\n",
        "\n",
        "Fill in the code below to plot the spectral power distribution of the light source D65."
      ],
      "metadata": {
        "id": "-jPlyl2oVflN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x = ... \n",
        "# y = ...\n",
        "plot_spectrum(x, y, ylabel='Relative Power $E(\\lambda)$')"
      ],
      "metadata": {
        "id": "gpDAq4iWW81M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the plot you obtain, you can see the correspondence between wavelength and the _perceived_ color of light. Note that light sources often emit light at wavelengths outside the visible spectrum, i.e., $\\lambda<380$ or $\\lambda>740$."
      ],
      "metadata": {
        "id": "Zao06eitXmxI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKoeqGH2W8Dc"
      },
      "source": [
        "Fill in the code below to plot the 3 other spectral power distributions.\n",
        "\n",
        "_Note:_ the provided spectral power distributions may differ in the grid of wavelengths measured."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for light_source in [\"A\", \"D50\", \"F2\"]:\n",
        "    filepath = os.path.join('illuminants', f'{light_source}.npy')\n",
        "    # ... Write your code here. Load the file and visualize the spectrum\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lBQp9LivXqXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which types of light sources do A, D50, D65, and F2 correspond to?\n",
        "\n",
        "_Hint_: https://en.wikipedia.org/wiki/Standard_illuminant"
      ],
      "metadata": {
        "id": "ewNtZIRtYzoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer: ..."
      ],
      "metadata": {
        "id": "ASwVI7YYZI8o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr1IT1kyX9wB"
      },
      "source": [
        "## Reflectance\n",
        "\n",
        "The color of a (non-transparent) object is characterized by its surface reflectance $S(λ)$, ($S(λ) ∈ [0, 1])$.\n",
        "\n",
        "For each wavelength or wavelength interval, a reflectance factor indicates how  much of the incoming radiation is reflected.\n",
        "\n",
        "By shining a white light on an object, its reflectance can be measured at various wavelengths. \n",
        "\n",
        "\n",
        "We provide you 2 files, `CDREF31_persilcolour.npy` and `CDREF31_unclebens.npy`.\n",
        "\n",
        "These files contain _hyperspectral_ images, i.e., measurements of reflectance at various wavelengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UHR7fUygCJF"
      },
      "source": [
        "!ls reflectance_images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Those files can be loaded as follow:"
      ],
      "metadata": {
        "id": "S2Lv8e6LbS5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spectral_image = np.load(os.path.join('reflectance_images', 'CDREF31_persilcolour.npy'))"
      ],
      "metadata": {
        "id": "ircfrP_cbR4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the shape of the array `spectral_image`? What does each dimension correspond to? \n",
        "How many pixels does the image have? At how many wavelengths the reflectance was measured?"
      ],
      "metadata": {
        "id": "MMImOt42budq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... Write your code here"
      ],
      "metadata": {
        "id": "ov7gHb-tcWeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer: ..."
      ],
      "metadata": {
        "id": "RRQJ6P33cYZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the minimal and maximal value stored in `spectral_image`? Does it make sense to you?"
      ],
      "metadata": {
        "id": "Nd1kcP-UOfv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ... Write your code here"
      ],
      "metadata": {
        "id": "QSbf1vIrOZ-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer: ..."
      ],
      "metadata": {
        "id": "VloZ1lYBOsYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get an idea of the object being photographed, visualize below the average intensity, averaged over all wavelengths."
      ],
      "metadata": {
        "id": "jjNncyVMcq70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,6))\n",
        "# average_intensity = ... Hint: It must be a 2D array with the same spatial dimensions as `image`\n",
        "plt.imshow(average_intensity,  vmin=0., vmax=1., cmap='Greys_r')"
      ],
      "metadata": {
        "id": "Jdnut0Scc0ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By choosing a specific pixel location $x$, you can visualize the relative reflectance $S(x, \\lambda)$ along the spectrum at that position (e.g., $x=(50,130)$):"
      ],
      "metadata": {
        "id": "CEJ1ai_gdNXX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7waGKrtM63e"
      },
      "source": [
        "wavelengths = np.arange(400,710,10)\n",
        "reflectance_spectrum = spectral_image[:,50,130]\n",
        "plot_spectrum(wavelengths, reflectance_spectrum, ylabel='Reflectance factor $S(x, \\lambda)$')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, show the reflectance spectra $S(x, \\lambda)$ for the following pixel locations: \n",
        "\n",
        "$x = (40, 15)$; \n",
        "$x = (227, 296)$; \n",
        "$x = (100, 125)$ and\n",
        "$x = (36, 100)$."
      ],
      "metadata": {
        "id": "4JTfFVA_dx43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pixel_location in [(40, 15), (227, 296), (100, 125), (36, 100)]:\n",
        "    plt.figure()\n",
        "    # x = ... Write your code here\n",
        "    # y = ... Write your code here\n",
        "    # ... Plot the spectrum"
      ],
      "metadata": {
        "id": "IDSYo2SxPcCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on those reflectance spectra, try to guess the color of those pixels."
      ],
      "metadata": {
        "id": "tfCoLT-pQIhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answer: ..."
      ],
      "metadata": {
        "id": "ClZ9kao_QT9A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PyqfTcZZBsa"
      },
      "source": [
        "## Sensors\n",
        "\n",
        "The perception of light is enabled by photo-sensitive sensors, which respond to light by emitting an electric charge. The strength of this response varies by wavelength, and is characterized by the _sensitivity_ of the sensor, $R(\\lambda)$. \n",
        "\n",
        "We provide you 2 files, `cone_sensitivity.npy` and `camera_sensitivity.npy`.\n",
        "\n",
        "The file `cone_sensitivity.npy` contains the sensitivities of the 3 types of cones in the Human Vision.\n",
        "\n",
        "The file `camera_sensitivity.npy` contains the sensitivities of the 3 channels R, G and B, of the camera sensor (including filters)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v73XqF-XZYXs"
      },
      "source": [
        "### Camera\n",
        "\n",
        "The silicon-based camera sensor is placed behind a filter which allows only certain wavelengths to go through. These filters (of which, uncoincidentally there are 3) correspond largely to <b>R</b>ed, <b>G</b>reen, <b>B</b>lue. `camera_sensitivity` has 3 columns, each corresponding to the sensitivity of the sensor when placed behind a different filter, measured at various wavelengths:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wghe7acZOOho"
      },
      "source": [
        "wavelengths = np.arange(400,710,10)\n",
        "camera_sensitivity = np.load(os.path.join(\"sensitivities\", 'camera_sensitivity.npy'))\n",
        "print(wavelengths.shape, camera_sensitivity.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_qRtjwNZiRI"
      },
      "source": [
        "These sensitivity curves are shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXw8H-DqORqT"
      },
      "source": [
        "wavelengths = np.arange(400,710,10)\n",
        "plt.figure(figsize=(15,4))\n",
        "for i, channel in enumerate(('R', 'G', 'B')):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plot_spectrum(wavelengths, camera_sensitivity[:,i], ylabel='Sensitivity' if i==0 else None)\n",
        "    plt.title(channel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Human Vision System"
      ],
      "metadata": {
        "id": "NjqCITAlfmul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cones sensitivity\n",
        "\n",
        "The _cone_ cells of the human eye system are of three distinct types, distinguished by their sensitivity."
      ],
      "metadata": {
        "id": "MpCqA9B6SpPK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGs3KM8vOHdf"
      },
      "source": [
        "wavelengths = np.arange(400,710,10)\n",
        "cone_sensitivity = np.load(os.path.join(\"sensitivities\", 'cone_sensitivity.npy'))\n",
        "print(wavelengths.shape, camera_sensitivity.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcgC0xN7ZNaY"
      },
      "source": [
        "`cone_sensitivity` has 3 columns, corresponding to the sensitivity of each type of cone: <b>L</b>ong, <b>M</b>edium, and <b>S</b>hort. The names of these types of cones indicate the wavelength of maximal response. Fill in the code below to plot the sensitivity of the 3 types cone cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAm68uLvOMcS"
      },
      "source": [
        "plt.figure(figsize=(15,4))\n",
        "for i, channel in enumerate(('L', 'M', 'S')):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    #... Plot the spectrum\n",
        "    plt.title(channel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Color matching functions $\\bar{x}$, $\\bar{y}$, $\\bar{z}$\n",
        "\n",
        "Before researchers understood the biology of the _cone_ cells of the human eye system, they conducted in 1931 color matching experiments and therefore the CIE 1931 XYZ color space was introduced as an average observer sensitivity.  Those color matching functions $\\bar{x}(\\lambda)$, $\\bar{y}(\\lambda)$ and $\\bar{z}(\\lambda)$ are used today as idealized basic functions (primaries) for different color encodings.\n"
      ],
      "metadata": {
        "id": "bzeE614YTqOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cie_xyz = np.genfromtxt(os.path.join(\"sensitivities\", 'ciexyz31_1.csv'), delimiter=',')\n",
        "wavelengths = cie_xyz[:, 0]\n",
        "xyz_sensitivity = cie_xyz[:, 1:4]\n",
        "print(wavelengths.shape, xyz_sensitivity.shape)"
      ],
      "metadata": {
        "id": "Ysf0hifsUElx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Those 3 color matching functions can be thought of as sensitivity curves:"
      ],
      "metadata": {
        "id": "rv7dq-0aV-xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,4))\n",
        "for i, channel in enumerate((r'$\\bar{x}$', r'$\\bar{y}$', r'$\\bar{z}$')):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plot_spectrum(wavelengths, xyz_sensitivity[:,i], ylabel='\"Sensitivity\"' if i==0 else None)\n",
        "    plt.title(channel)"
      ],
      "metadata": {
        "id": "06shwGeiV-bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MikgcK8wZyvp"
      },
      "source": [
        "## Image formation\n",
        "\n",
        "The final color response $\\rho_\\kappa$ of a sensor $\\kappa$ with sensitivity $R_\\kappa(\\lambda)$ in response to light reflecting off a point $x$ with reflectance $S(x, \\lambda)$, under a light source with spectral power distribution $E(\\lambda)$ is:\n",
        "\n",
        "$\\rho_\\kappa= \\int_\\lambda R(\\lambda)S(x, \\lambda)E(\\lambda)~d\\lambda$\n",
        "\n",
        "Note that this model of the color response considers an integral over a continuous spectrum. In practice, however, the response is computed discretely, by summing over $\\lambda$ over a sampling grid $\\Lambda$. $\\rho_\\kappa$ is also normalized so that $\\text{max}_{\\kappa\\in\\text{sensors}}(\\rho_\\kappa)=1$. This leads to:\n",
        "\n",
        "$\\rho_\\kappa= n \\sum_{\\lambda\\in\\Lambda} R(\\lambda)S(x, \\lambda)E(\\lambda)~~~$ \n",
        "for $\\Lambda = \\{400 + i\\cdot10 | 0\\leq i\\leq 30, i\\in\\mathcal{N}\\}$\n",
        "\n",
        "where $n$ is a normalization factor.\n",
        "\n",
        "Fill in the code below to compute the RGB image for the loaded spectral image and illuminant."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image in LMS Color Space\n",
        "\n",
        "Now we want to form an image using the cone sensitivities to aggregate different wavelengths\n",
        "\n",
        "Fill in the code below to compute the RGB image for the loaded spectral image and illuminant.\n"
      ],
      "metadata": {
        "id": "X-WkRuU2xPq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wavelengths = np.arange(400,710,10)\n",
        "cone_sensitivity = np.load(os.path.join(\"sensitivities\", 'cone_sensitivity.npy'))\n",
        "spectral_image = np.load(os.path.join('reflectance_images', 'CDREF31_persilcolour.npy'))\n",
        "illuminant = np.load(os.path.join('illuminants', 'D65.npy'))\n",
        "illuminant = illuminant[np.isin(illuminant[:,0], wavelengths), 1]\n",
        "print(wavelengths.shape, camera_sensitivity.shape, spectral_image.shape, illuminant.shape)"
      ],
      "metadata": {
        "id": "YcxCbL0wx_26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ...\n",
        "# rho_L = ... Write your code here\n",
        "# rho_M = ... Write your code here\n",
        "# rho_S = ... Write your code here\n",
        "# ...\n",
        "\n",
        "result_LMS = np.stack((rho_L, rho_M, rho_S)).transpose(1, 2, 0)\n",
        "n = 1/result_LMS.max() # normalization factor n\n",
        "result_LMS *= n\n",
        "\n",
        "print(\"Normalization Factor = \", n)\n",
        "\n",
        "assert result_LMS.shape == (256, 336, 3)"
      ],
      "metadata": {
        "id": "x5t1K5dy18_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`result_LMS` is now a valid RGB image and can be visualized:"
      ],
      "metadata": {
        "id": "bUlBhHcR1kXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(21,6))\n",
        "for i, channel in enumerate(('R', 'G', 'B')):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(result_LMS[:,:,i],  vmin=0., vmax=1., cmap='Greys_r')\n",
        "    plt.title(channel)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.imshow(result_LMS, vmin=0., vmax=1.)"
      ],
      "metadata": {
        "id": "blZcA4g31UiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image in RGB Color Space\n",
        "\n",
        "Now we want to form an image using the camera sensitivities to aggregate different wavelengths\n",
        "\n",
        "Fill in the code below to compute the RGB image for the loaded spectral image and illuminant."
      ],
      "metadata": {
        "id": "UB2DNB66fdKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wavelengths = np.arange(400,710,10)\n",
        "camera_sensitivity = np.load(os.path.join(\"sensitivities\", 'camera_sensitivity.npy'))\n",
        "spectral_image = np.load(os.path.join('reflectance_images', 'CDREF31_persilcolour.npy'))\n",
        "illuminant = np.load(os.path.join('illuminants', 'D65.npy'))\n",
        "illuminant = illuminant[np.isin(illuminant[:,0], wavelengths), 1]\n",
        "print(wavelengths.shape, camera_sensitivity.shape, spectral_image.shape, illuminant.shape)"
      ],
      "metadata": {
        "id": "lIBUZSaveTJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mqckYjxOTqL"
      },
      "source": [
        "# ...\n",
        "# rho_R = ... Write your code here\n",
        "# rho_G = ... Write your code here\n",
        "# rho_B = ... Write your code here\n",
        "# ...\n",
        "\n",
        "result_RGB = np.stack((rho_R, rho_G, rho_B)).transpose(1, 2, 0)\n",
        "n = 1/result_RGB.max() # normalization factor n\n",
        "result_RGB *= n\n",
        "\n",
        "print(\"Normalization Factor = \", n)\n",
        "\n",
        "assert result_RGB.shape == (256, 336, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Why is the normalization factor for RGB color space is bigger than the normalization factor for LMS color space?\n",
        "\n",
        "Your answer: "
      ],
      "metadata": {
        "id": "XlPFdb9J5P5E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nft5uUTqaBTQ"
      },
      "source": [
        "`result_RGB` is now a valid RGB image and can be visualized:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(21,6))\n",
        "for i, channel in enumerate(('R', 'G', 'B')):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(result_RGB[:,:,i],  vmin=0., vmax=1., cmap='Greys_r')\n",
        "    plt.title(channel)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.imshow(result_RGB, vmin=0., vmax=1.)"
      ],
      "metadata": {
        "id": "vcFbtu69gsHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vNdyP-WaJ6v"
      },
      "source": [
        "A little dark? That is because we have yet to apply gamma-correction, to compensate for how computer monitors interpret RGB values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7eNX_mjOYa0"
      },
      "source": [
        "plt.figure(figsize=(7,6))\n",
        "plt.imshow(result_RGB**(1/2.2), vmin=0., vmax=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFG-LtE2aSgp"
      },
      "source": [
        "Question: Why do the colors look very different between the images formed using cone sensitivities and the camera sensitivities? Explain the difference. \n",
        "\n",
        "Your answer: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image in CIE 1931 XYZ color space\n",
        "\n",
        "Fill in the code below to visualize the image in CIE 1931 XYZ color space."
      ],
      "metadata": {
        "id": "kM7Fadibi_sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wavelengths = np.arange(400,710,10)\n",
        "cie_xyz = np.genfromtxt(os.path.join(\"sensitivities\", 'ciexyz31_1.csv'), delimiter=',')\n",
        "xyz_sensitivity = cie_xyz[np.isin(cie_xyz[:,0], wavelengths), 1:4]\n",
        "spectral_image = np.load(os.path.join(\"reflectance_images\", 'CDREF31_persilcolour.npy'))\n",
        "illuminant = np.load(os.path.join('illuminants', 'D65.npy'))\n",
        "illuminant = illuminant[np.isin(illuminant[:,0], wavelengths), 1]\n",
        "print(wavelengths.shape, xyz_sensitivity.shape, spectral_image.shape, illuminant.shape)"
      ],
      "metadata": {
        "id": "mCQXMXs1gY7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ...\n",
        "# rho_X = ... Write your code here\n",
        "# rho_Y = ... Write your code here\n",
        "# rho_Z = ... Write your code here.\n",
        "# ...\n",
        "\n",
        "result_XYZ = np.stack((rho_X, rho_Y, rho_Z)).transpose(1, 2, 0)\n",
        "n = 1/result_XYZ.max() # normalization factor n\n",
        "result_XYZ *= n\n",
        "assert result_XYZ.shape == (256, 336, 3)"
      ],
      "metadata": {
        "id": "p8YGQ5Blh08h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(21,6))\n",
        "for i, channel in enumerate(('R', 'G', 'B')):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(result_XYZ[:,:,i],  vmin=0., vmax=1., cmap='Greys_r')\n",
        "    plt.title(channel)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.imshow(result_XYZ, vmin=0., vmax=1.)"
      ],
      "metadata": {
        "id": "L4eNygKiiEXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Explain the color difference between the images formed using RGB camera sensitivities and XYZ sensitivities.\n",
        "\n",
        "Your answer: "
      ],
      "metadata": {
        "id": "UGUtsnJ06edj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image in sRGB and CIE L\\*a\\*b\\* color spaces\n",
        "\n",
        "If you computed the image correctly in the CIE 1931 XYZ color space, the code below should display the image in sRGB and CIE L\\*a\\*b\\* color spaces."
      ],
      "metadata": {
        "id": "TPHgpC3Jibpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import xyz2rgb, rgb2lab\n",
        "RGBresult  = xyz2rgb(result_XYZ)\n",
        "LABresult = rgb2lab(RGBresult)"
      ],
      "metadata": {
        "id": "2yzprV2KiNrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(21,6))\n",
        "for i, channel in enumerate(('R', 'G', 'B')):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(RGBresult[:,:,i], vmin=0., vmax=1., cmap='Greys_r')\n",
        "    plt.title(channel)   \n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.imshow(RGBresult) "
      ],
      "metadata": {
        "id": "_3-KAAOXkOSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(21,6))\n",
        "for i, channel in enumerate(('L*', 'a*', 'b*')):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(LABresult[:,:,i], cmap='Greys_r')\n",
        "    plt.title(channel)   "
      ],
      "metadata": {
        "id": "XhJZ6Ip2kUso"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}